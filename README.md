# HPCv3 Simulator ğŸ–¥ï¸âš¡

HPCv3 is a lightweight simulator for studying **job scheduling** and **resource allocation** in High-Performance Computing (HPC) systems.  
It allows you to **generate workloads**, **define platforms**, **convert swf formats to JSON**, **run scheduling simulations** with different algorithms, and **visualize results**.

## ğŸ“¥ Installation

### Prerequisites

- Python 3.9 or newer
- Recommended: create a virtual environment to isolate dependencies

### Clone and Setup Environment

```bash
git clone https://github.com/algoritmakomputasi-ugm/HPCv3-AIBT-2025.git
cd HPCv3-AIBT-2025
python setup.py
```

## âš™ï¸ Workflow Overview

Workload Generation â†’ Define synthetic job traces.

Platform Generation â†’ Define HPC platform topology and machine states.

Scheduling Simulation â†’ Run the simulation with different schedulers.

Results Visualization â†’ Analyze and visualize scheduling outcomes.

Each stage is provided as a Jupyter Notebook for ease of experimentation.

## ğŸ“‚ Workload Generation

Notebook: `workloads_generator.ipynb`

This stage generates job traces that describe:

- Number of jobs
- Arrival times
- Job duration
- Resource requirements

You can configure parameters (e.g., inter-arrival rate, job length distribution) to model different HPC workloads.
The output is stored as a .json or .csv file, which will be used as input for the simulation.

## ğŸ—ï¸ Platform Generation

Notebook: `platforms_generator.ipynb`

This stage defines the HPC platform, including:

- Number of compute nodes
- Available DVFS (Dynamic Voltage and Frequency Scaling) profiles
- Power consumption and compute speed
- The generated platform description file is also saved as .json, providing the environment where jobs will be scheduled.

## ğŸ’» Scheduling Simulation

Notebook: `SPARS_runner.ipynb`

Here you run the simulation by combining:

- A workload file (jobs to run)
- A platform file (system configuration)
- A scheduler of your choice

Available schedulers:

1. **Easy Backfilling** â€“ Improves utilization by allowing smaller jobs to jump ahead if they donâ€™t delay larger jobs.
2. **FCFS (First-Come, First-Served)** â€“ Jobs are executed in the order they arrive.
3. **Smart FCFS** â€“ An enhanced FCFS variant with an early switch-on policy.

The simulation produces CSV logs containing job start/finish times, node allocations, and system events.

## ğŸ“Š Results Visualization

Notebook: create_ganttchart.ipynb

This stage transforms raw CSV logs into visual insights.
Outputs include:

- Gantt chart â†’ shows job execution timelines and node allocations
- Job statistics â†’ execution time, waiting time, utilization
- Energy consumption analysis (if DVFS/platform states are enabled)

These visualizations help you evaluate the effectiveness of different scheduling policies and platform configurations.

## ğŸš€ Example End-to-End Run

1. Generate a workload â†’ `workloads_generator.ipynb`
2. Generate a platform â†’ `platforms_generator.ipynb`
3. Run simulation â†’ `HPCv3_runner.ipynb`
4. Visualize results â†’ `create_ganttchart.ipynb`

## Additional SWF to JSON converter

The notebook `swf_to_json.ipynb` lets you convert SWF format files into JSON files.

## ğŸ“ License

MIT License â€“ feel free to use and extend for research and teaching.  
Please provide appropriate credit when using or modifying this project in your own work.
